# app/services.py (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
import asyncio
import hashlib
import time
import re
import os
import tempfile
import subprocess
from typing import Dict, Any, Optional, List
from urllib.parse import urlparse, urlsplit, urlunsplit, parse_qsl, urlencode

from app.database import db_manager
from app.external_apis.manager import external_api_manager
from app.logger import logger
from app.validators import security_validator
from app.cache import disk_cache

class AnalysisService:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤–Ω–µ—à–Ω–∏—Ö API
    """
    
    # –ö–†–ò–¢–ò–ß–ù–û: Whitelist –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞–∫ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö
    TRUSTED_DOMAINS = {
        'google.com', 'youtube.com', 'github.com', 'microsoft.com',
        'apple.com', 'mozilla.org', 'wikipedia.org', 'stackoverflow.com',
        'amazon.com', 'facebook.com', 'twitter.com', 'linkedin.com',
        'reddit.com', 'netflix.com', 'spotify.com', 'discord.com',
        'cloudflare.com', 'akamai.com', 'fastly.com'
    }
    
    # –î–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø–æ–¥–¥–æ–º–µ–Ω—ã (–ª—é–±–æ–π –ø–æ–¥–¥–æ–º–µ–Ω —ç—Ç–∏—Ö –¥–æ–º–µ–Ω–æ–≤ —Ç–∞–∫–∂–µ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–π)
    TRUSTED_DOMAIN_SUFFIXES = [
        '.google.com', '.youtube.com', '.github.com', '.microsoft.com',
        '.apple.com', '.mozilla.org', '.wikipedia.org', '.stackoverflow.com',
        '.amazon.com', '.facebook.com', '.twitter.com', '.linkedin.com',
        '.cloudflare.com', '.akamai.com', '.fastly.com'
    ]
    
    def __init__(self, use_external_apis: bool = True):
        self.use_external_apis = use_external_apis
        # –ü—Ä–æ—Å—Ç–æ–π in-memory –∫—ç—à: –∫–ª—é—á -> (–∏—Å—Ç–µ–∫–∞–µ—Ç_–≤_–º—Å, —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
        self._cache: Dict[str, Any] = {}
        self._cache_ttl_seconds = 300
        # –ö–†–ò–¢–ò–ß–ù–û: –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Å source: local_only –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        try:
            disk_cache.delete_by_source("local_only")
        except Exception as e:
            logger.warning(f"Failed to clean old cache entries: {e}")
        # YARA –ø—Ä–∞–≤–∏–ª–∞ (–ø—Ä–æ—Å—Ç—ã–µ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã)
        self._yara_rules = self._load_yara_rules()
    
    def _is_trusted_domain(self, domain: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–º–µ–Ω –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º"""
        if not domain:
            return False
        domain_lower = domain.lower().strip()
        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if domain_lower in self.TRUSTED_DOMAINS:
            logger.debug(f"Trusted domain match (exact): {domain_lower}")
            return True
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–æ–º–µ–Ω–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, www.google.com, mail.google.com)
        for suffix in self.TRUSTED_DOMAIN_SUFFIXES:
            if domain_lower.endswith(suffix):
                logger.debug(f"Trusted domain match (suffix): {domain_lower} ends with {suffix}")
                return True
        return False

    # ---------------------- –£—Ç–∏–ª–∏—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∑–∞—â–∏—Ç—ã ----------------------

    @staticmethod
    def _is_private_or_internal_url(url: str) -> bool:
        """–ë–ª–æ–∫–∏—Ä—É–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö/–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö URL –≤–æ –≤–Ω–µ—à–Ω–∏–µ API (VT, GSB –∏ —Ç.–¥.)."""
        try:
            parsed = urlparse(url)
            host = (parsed.hostname or "").lower()
            path = (parsed.path or "").lower()

            if not host:
                return False

            # –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏ –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ —Å–µ—Ç–∏
            private_hosts_prefixes = ("127.", "10.", "192.168.", "172.16.", "172.17.", "172.18.", "172.19.",
                                      "172.20.", "172.21.", "172.22.", "172.23.", "172.24.", "172.25.",
                                      "172.26.", "172.27.", "172.28.", "172.29.", "172.30.", "172.31.")
            if host == "localhost" or host.startswith(private_hosts_prefixes):
                return True

            # –Ø–≤–Ω–æ –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –ø—É—Ç–∏
            private_path_fragments = [
                "/admin", "/internal", "/dashboard", "/keys",
                "/auth", "/config", "/api"
            ]
            if any(fragment in path for fragment in private_path_fragments):
                return True

            return False
        except Exception:
            return False

    @staticmethod
    def _normalize_url_for_analysis(url: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫—ç—à–∞:
        - –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        - —É–¥–∞–ª–µ–Ω–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (#...)
        - —É–¥–∞–ª–µ–Ω–∏–µ UTM/—Ç—Ä–µ–∫–µ—Ä–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        - –¥–æ–º–µ–Ω–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞ (Google, YouTube –∏ —Ç.–ø.)
        """
        try:
            parts = urlsplit(url)
            scheme = parts.scheme
            netloc = parts.netloc.lower()
            path = parts.path or ""
            query = parts.query or ""

            # –ü–∞—Ä—Å–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            query_pairs = parse_qsl(query, keep_blank_values=True)

            # –û–±—â–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            tracking_prefixes = ("utm_",)
            tracking_exact = {
                "gclid", "fbclid", "yclid", "mc_cid", "mc_eid",
                "utm_referrer", "_hsenc", "_hsmi", "spm"
            }

            def is_tracking_param(name: str) -> bool:
                return name.startswith(tracking_prefixes) or name in tracking_exact

            domain = netloc

            # Google search: —É–¥–∞–ª—è–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–º–µ–Ω –∏ –ø—É—Ç—å
            if "google." in domain:
                filtered_pairs: List = []
            # YouTube: –¥–ª—è watch-—Å—Å—ã–ª–æ–∫ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ v (id –≤–∏–¥–µ–æ)
            elif "youtube.com" in domain or domain == "youtu.be":
                keep_names = {"v"}
                filtered_pairs = [(k, v) for (k, v) in query_pairs if k in keep_names]
            else:
                # –£–¥–∞–ª—è–µ–º —Ç—Ä–µ–∫–∏–Ω–≥-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                filtered_pairs = [(k, v) for (k, v) in query_pairs if not is_tracking_param(k)]

            normalized_query = urlencode(filtered_pairs, doseq=True)

            # –§—Ä–∞–≥–º–µ–Ω—Ç –≤—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º
            normalized = urlunsplit((scheme, netloc, path, normalized_query, ""))
            return normalized
        except Exception:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π URL
            return url

    def _cache_get(self, key: str) -> Optional[Dict[str, Any]]:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º in-memory –∫—ç—à
        item = self._cache.get(key)
        if item:
            expires_at_ms, value = item
            if time.time() * 1000 > expires_at_ms:
                self._cache.pop(key, None)
                return None
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–µ–Ω
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å safe: True –µ—Å–ª–∏ source –Ω–µ "combined" –∏–ª–∏ "external_apis"
            # –¢–∞–∫–∂–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ª—é–±—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å source: "local_only" (—Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ)
            if value and isinstance(value, dict):
                cached_safe = value.get("safe")
                cached_source = value.get("source", "")
                if cached_source == "local_only":
                    logger.warning(f"Ignoring cached result with invalid source=local_only for {key}")
                    self._cache.pop(key, None)
                    disk_cache.delete(key)
                    return None
                elif cached_safe is True and cached_source not in ("combined", "external_apis"):
                    logger.warning(f"Ignoring cached safe=True result with source={cached_source} for {key}")
                    self._cache.pop(key, None)
                    disk_cache.delete(key)
                    return None
            return value
        
        # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Å–∫-–∫—ç—à
        disk_result = disk_cache.get(key)
        if disk_result:
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–µ–Ω
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å safe: True –µ—Å–ª–∏ source –Ω–µ "combined" –∏–ª–∏ "external_apis"
            # –¢–∞–∫–∂–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ª—é–±—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å source: "local_only" (—Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ)
            if disk_result and isinstance(disk_result, dict):
                cached_safe = disk_result.get("safe")
                cached_source = disk_result.get("source", "")
                if cached_source == "local_only":
                    logger.warning(f"Ignoring cached result with invalid source=local_only for {key}")
                    disk_cache.delete(key)
                    return None
                elif cached_safe is True and cached_source not in ("combined", "external_apis"):
                    logger.warning(f"Ignoring cached safe=True result with source={cached_source} for {key}")
                    disk_cache.delete(key)
                    return None
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ in-memory –∫—ç—à
            self._cache_set(key, disk_result)
            return disk_result
        
        return None

    def _cache_set(self, key: str, value: Dict[str, Any]):
        expires_at_ms = int(time.time() * 1000 + self._cache_ttl_seconds * 1000)
        self._cache[key] = (expires_at_ms, value)
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –¥–∏—Å–∫-–∫—ç—à
        disk_cache.set(key, value, self._cache_ttl_seconds)

    def _load_yara_rules(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ YARA-–ø–æ–¥–æ–±–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        return [
            {
                "name": "suspicious_pe_header",
                "pattern": b"MZ",
                "description": "Windows PE executable detected",
                "threat_score": 20
            },
            {
                "name": "powershell_script",
                "pattern": b"powershell",
                "description": "PowerShell script detected",
                "threat_score": 30
            },
            {
                "name": "base64_encoded",
                "pattern": b"base64",
                "description": "Base64 encoded content detected",
                "threat_score": 15
            },
            {
                "name": "suspicious_urls",
                "pattern": b"http://",
                "description": "HTTP URLs detected (potentially suspicious)",
                "threat_score": 10
            }
        ]

    def _scan_with_yara_rules(self, file_content: bytes) -> Dict[str, Any]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ—Å—Ç—ã—Ö YARA-–ø–æ–¥–æ–±–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª"""
        detected_rules = []
        total_threat_score = 0
        
        for rule in self._yara_rules:
            if rule["pattern"] in file_content:
                detected_rules.append({
                    "rule_name": rule["name"],
                    "description": rule["description"],
                    "threat_score": rule["threat_score"]
                })
                total_threat_score += rule["threat_score"]
        
        return {
            "detected_rules": detected_rules,
            "total_threat_score": total_threat_score,
            "is_suspicious": total_threat_score > 50
        }
    
    async def analyze_url(self, url: str, use_external_apis: bool = None, ignore_database: bool = False) -> Dict[str, Any]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ URL —Å –≤–Ω–µ—à–Ω–∏–º–∏ API
        
        Args:
            url: URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            use_external_apis: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –≤–Ω–µ—à–Ω–∏–µ API
            ignore_database: –ï—Å–ª–∏ True, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ –ë–î –∏ –¥–µ–ª–∞–µ—Ç –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        """
        try:
            logger.info(f"üîç Analyzing URL: {url} (ignore_db={ignore_database})")
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL
            url = self._normalize_url_for_analysis(url)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ö—ç—à - –Ω–æ –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å safe: True
            # –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–Ω–µ—à–Ω–∏—Ö API
            cache_key = f"url:{url}"
            cached = self._cache_get(cache_key)
            if cached is not None and not ignore_database:
                # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–µ–µ—Ç safe: True, –Ω–æ source –Ω–µ "combined" –∏–ª–∏ "external_apis",
                # –∑–Ω–∞—á–∏—Ç –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–Ω–µ—à–Ω–∏—Ö API - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –µ–≥–æ
                # –¢–∞–∫–∂–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ª—é–±—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å source: "local_only" (—Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ)
                cached_safe = cached.get("safe")
                cached_source = cached.get("source", "")
                if cached_source == "local_only":
                    logger.warning(f"Ignoring cached result with invalid source=local_only for {url}, re-analyzing")
                    # –£–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑
                    self._cache.pop(cache_key, None)
                    disk_cache.delete(cache_key)
                elif cached_safe is True and cached_source not in ("combined", "external_apis"):
                    logger.warning(f"Ignoring cached safe=True result with source={cached_source} for {url}, re-analyzing")
                    # –£–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑
                    self._cache.pop(cache_key, None)
                    disk_cache.delete(cache_key)
                else:
                    return cached
            
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ ignore_database=True)
            if not ignore_database:
                try:
                    url_threat = db_manager.check_url(url)
                    if url_threat:
                        logger.info(f"‚ö†Ô∏è URL found in database as malicious: {url}")
                        return {
                            "safe": False,
                            "threat_type": url_threat["threat_type"],
                            "details": f"Local database: {url_threat['description']}",
                            "source": "local_db"
                        }
                except Exception as db_error:
                    logger.warning(f"Database check failed: {db_error}")
            else:
                logger.info(f"üîÑ Ignoring database check for {url} (forced re-analysis)")
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–º–µ–Ω–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ
            parsed_url = urlparse(url)
            domain = parsed_url.netloc.lower()
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ - –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞–∫ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö
            if self._is_trusted_domain(domain):
                logger.info(f"‚úÖ Trusted domain detected: {domain} - marking as safe immediately")
                result = {
                    "safe": True,
                    "threat_type": None,
                    "details": f"Trusted domain: {domain}",
                    "source": "trusted_domain",
                    "confidence": 95
                }
                self._cache_set(cache_key, result)
                return result
            
            try:
                domain_threats = db_manager.check_domain(domain)
                if domain_threats:
                    return {
                        "safe": False,
                        "threat_type": domain_threats[0]["threat_type"],
                        "details": f"Domain {domain} has {len(domain_threats)} known threats",
                        "source": "local_db"
                    }
            except Exception as db_error:
                logger.warning(f"Database domain check failed: {db_error}")
            
            # 3. –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö/–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö URL –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö API (–∑–∞—â–∏—Ç–∞ –æ—Ç —É—Ç–µ—á–µ–∫)
            if self._is_private_or_internal_url(url):
                logger.warning(f"‚ö†Ô∏è Private/internal URL detected, skipping external APIs: {url}")
                # –î–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö URL –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º
                # –ö–†–ò–¢–ò–ß–ù–û: domain —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤—ã—à–µ
                heuristic_result = self._url_heuristic_analysis(url, domain)
                heuristic_safe = heuristic_result.get("safe")
                if heuristic_safe is False:
                    result = {
                        "safe": False,
                        "threat_type": "suspicious",
                        "details": "Private/internal URL with suspicious indicators",
                        "source": "internal_heuristic",
                        "confidence": 60,
                        "external_scans": {}
                    }
                else:
                    # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ URL –±–µ–∑ —á–µ—Ç–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ (–æ–Ω–∏ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –Ω–∞—Ä—É–∂—É)
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": "Private/internal URL - not sent to external security services",
                        "source": "internal_only",
                        "confidence": 70,
                        "external_scans": {}
                    }
                self._cache_set(cache_key, result)
                return result

            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ –≤–Ω–µ—à–Ω–∏–µ API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            external_result = None
            should_use_external = use_external_apis if use_external_apis is not None else self.use_external_apis
            if should_use_external:
                try:
                    logger.info(f"üîç Checking external APIs for: {url}")
                    external_result = await asyncio.wait_for(
                        external_api_manager.check_url_multiple_apis(url), 
                        timeout=8.0
                    )
                    logger.info(f"üîç External API result: safe={external_result.get('safe')}, threat_type={external_result.get('threat_type')}")
                    
                    # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º safe —è–≤–Ω–æ, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—è default True
                    external_safe = external_result.get("safe")
                    if external_safe is False or (external_safe is None and external_result.get("threat_type")):
                        logger.warning(f"üö® External APIs detected threat for {url}: {external_result}")
                        try:
                            threat_type = external_result.get("threat_type", "malware")
                            if threat_type == "malicious":
                                threat_type = "malware"
                            db_manager.add_malicious_url(
                                url,
                                threat_type,
                                external_result.get("details", "Detected by external scan"),
                            )
                        except Exception as save_err:
                            logger.error(f"Failed to persist URL threat: {save_err}")
                        return {
                            **external_result,
                            "safe": False,  # –Ø–≤–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º False
                            "source": "external_apis",
                            "confidence": external_result.get("confidence", 80)
                        }
                    elif external_safe is True:
                        logger.info(f"‚úÖ External APIs found {url} to be safe")
                    else:
                        logger.warning(f"‚ö†Ô∏è External APIs returned unclear result for {url}: safe={external_safe}")
                except asyncio.TimeoutError:
                    logger.error(f"External API check timed out for {url}")
                except Exception as e:
                    logger.error(f"External API check failed: {e}", exc_info=True)
            
            # 4. –õ–æ–∫–∞–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
            heuristic_result = self._url_heuristic_analysis(url, domain)
            
            # 5. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –ü–†–ò–û–†–ò–¢–ï–¢ –í–ù–ï–®–ù–ò–ú API
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º safe —è–≤–Ω–æ, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—è default True
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ –≤–Ω–µ—à–Ω–∏–µ API –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –∏–ª–∏ –Ω–µ –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç,
            # –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É - –µ—Å–ª–∏ –Ω–µ—Ç —É–≥—Ä–æ–∑, —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            if not should_use_external or not external_result:
                logger.warning(f"External APIs {'disabled' if not should_use_external else 'did not return result'} for {url}, using heuristic analysis")
                heuristic_safe = heuristic_result.get("safe")
                if heuristic_safe is False:
                    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞ —É–≥—Ä–æ–∑—É - —Å—á–∏—Ç–∞–µ–º –æ–ø–∞—Å–Ω—ã–º
                    result = {
                        **heuristic_result,
                        "source": "heuristic",
                        "external_scans": {},
                        "confidence": min(heuristic_result.get("confidence", 50), 70)
                    }
                    self._cache_set(cache_key, result)
                    return result
                else:
                    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞—à–ª–∞ —É–≥—Ä–æ–∑ - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (–ª–µ–≥–∫–∞—è –ø–∞—Ä–∞–Ω–æ–π—è)
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": f"URL appears safe (heuristic only, external APIs {'disabled' if not should_use_external else 'unavailable'}): {heuristic_result.get('details', 'No suspicious indicators')}",
                        "source": "heuristic",
                        "confidence": 55,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ
                        "external_scans": {}
                    }
                    self._cache_set(cache_key, result)
                    return result
            
            # –ö–†–ò–¢–ò–ß–ù–û: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–Ω–µ—à–Ω–∏—Ö API
            external_safe = external_result.get("safe")
            if external_safe is False or (external_safe is None and external_result.get("threat_type")):
                result = {
                    **external_result,
                    "safe": False,  # –Ø–≤–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º False
                    "source": "external_apis",
                    "confidence": external_result.get("confidence", 80)
                }
                self._cache_set(cache_key, result)
                return result
            
            heuristic_safe = heuristic_result.get("safe")
            if heuristic_safe is False:
                result = {
                    **heuristic_result,
                    "source": "heuristic",
                    "external_scans": external_result.get("external_scans", {}) if external_result else {}
                }
                self._cache_set(cache_key, result)
                return result
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ –≤–Ω–µ—à–Ω–∏–µ API –≤–µ—Ä–Ω—É–ª–∏ safe=True, —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º
            # –î–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –≤—Å–µ API –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –≤–µ—Ä–Ω—É–ª safe=True - –±–µ–∑–æ–ø–∞—Å–Ω–æ
            if external_result and external_result.get("safe") is True:
                external_scans = external_result.get("external_scans", {})
                enabled_apis = [name for name, enabled in external_api_manager.enabled_apis.items() if enabled]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –≤—Å–µ—Ö –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö API
                if enabled_apis and all(api_name in external_scans for api_name in enabled_apis):
                    # –í—Å–µ API –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": "URL appears to be safe (local + external verification)",
                        "source": "combined",
                        "external_scans": external_scans,
                        "confidence": max(heuristic_result.get("confidence", 50), 
                                        external_result.get("confidence", 50))
                    }
                    self._cache_set(cache_key, result)
                    return result
                else:
                    # –ù–µ –≤—Å–µ API –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –≤–µ—Ä–Ω—É–ª safe=True - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                    logger.info(f"Not all external APIs returned results for {url}, but at least one returned safe=True, treating as safe")
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": "URL appears to be safe (partial external verification)",
                        "source": "combined",
                        "external_scans": external_scans,
                        "confidence": min(max(heuristic_result.get("confidence", 50), 
                                        external_result.get("confidence", 50)), 70)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ 70%
                    }
                    self._cache_set(cache_key, result)
                    return result
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ external_result –µ—Å—Ç—å, –Ω–æ safe –Ω–µ True –∏ –Ω–µ False - —ç—Ç–æ None –∏–ª–∏ –æ—à–∏–±–∫–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É - –µ—Å–ª–∏ –Ω–µ—Ç —É–≥—Ä–æ–∑, —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            if external_result and external_result.get("safe") is None:
                logger.warning(f"External APIs returned None for {url}, using heuristic analysis")
                heuristic_safe = heuristic_result.get("safe")
                if heuristic_safe is False:
                    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞ —É–≥—Ä–æ–∑—É - —Å—á–∏—Ç–∞–µ–º –æ–ø–∞—Å–Ω—ã–º
                    result = {
                        **heuristic_result,
                        "source": "heuristic",
                        "external_scans": external_result.get("external_scans", {}),
                        "confidence": min(heuristic_result.get("confidence", 50), 70)
                    }
                    self._cache_set(cache_key, result)
                    return result
                else:
                    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞—à–ª–∞ —É–≥—Ä–æ–∑ - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (–ª–µ–≥–∫–∞—è –ø–∞—Ä–∞–Ω–æ–π—è)
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": f"URL appears safe (heuristic only, external APIs unclear): {heuristic_result.get('details', 'No suspicious indicators')}",
                        "source": "heuristic",
                        "confidence": 60,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ
                        "external_scans": external_result.get("external_scans", {})
                    }
                    self._cache_set(cache_key, result)
                    return result
            
            # –ö–†–ò–¢–ò–ß–ù–û: –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å safe=True –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö API
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É - –µ—Å–ª–∏ –Ω–µ—Ç —É–≥—Ä–æ–∑, —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            if not external_result or external_result.get("safe") is None:
                heuristic_safe = heuristic_result.get("safe")
                if heuristic_safe is False:
                    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞ —É–≥—Ä–æ–∑—É - —Å—á–∏—Ç–∞–µ–º –æ–ø–∞—Å–Ω—ã–º
                    result = {
                        **heuristic_result,
                        "source": "heuristic",
                        "external_scans": external_result.get("external_scans", {}) if external_result else {},
                        "confidence": min(heuristic_result.get("confidence", 50), 70)
                    }
                    self._cache_set(cache_key, result)
                    return result
                else:
                    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞—à–ª–∞ —É–≥—Ä–æ–∑ - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (–ª–µ–≥–∫–∞—è –ø–∞—Ä–∞–Ω–æ–π—è)
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": f"URL appears safe (heuristic only, external APIs unavailable): {heuristic_result.get('details', 'No suspicious indicators')}",
                        "source": "heuristic",
                        "confidence": 55,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ
                        "external_scans": external_result.get("external_scans", {}) if external_result else {}
                    }
                    self._cache_set(cache_key, result)
                    return result
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–Ω—É–ª–∞ safe=True –ò –≤–Ω–µ—à–Ω–∏–µ API —Ç–æ–∂–µ safe=True, —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º
            # –î–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –≤—Å–µ API –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –≤–µ—Ä–Ω—É–ª safe=True - –±–µ–∑–æ–ø–∞—Å–Ω–æ
            if heuristic_safe is True and external_result.get("safe") is True:
                external_scans = external_result.get("external_scans", {})
                enabled_apis = [name for name, enabled in external_api_manager.enabled_apis.items() if enabled]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –≤—Å–µ—Ö –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö API
                if enabled_apis and all(api_name in external_scans for api_name in enabled_apis):
                    # –í—Å–µ API –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": "URL appears to be safe (local + external verification)",
                        "source": "combined",
                        "confidence": max(heuristic_result.get("confidence", 50), 
                                        external_result.get("confidence", 50)),
                        "external_scans": external_scans
                    }
                    self._cache_set(cache_key, result)
                    return result
                else:
                    # –ù–µ –≤—Å–µ API –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –≤–µ—Ä–Ω—É–ª safe=True - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                    logger.info(f"Not all external APIs returned results for {url}, but at least one returned safe=True, treating as safe")
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": "URL appears to be safe (partial external verification)",
                        "source": "combined",
                        "confidence": min(max(heuristic_result.get("confidence", 50), 
                                        external_result.get("confidence", 50)), 70),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ 70%
                        "external_scans": external_scans
                    }
                    self._cache_set(cache_key, result)
                    return result
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É
            # –ï—Å–ª–∏ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞—à–ª–∞ —É–≥—Ä–æ–∑ - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            heuristic_safe = heuristic_result.get("safe")
            if heuristic_safe is False:
                # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞ —É–≥—Ä–æ–∑—É - —Å—á–∏—Ç–∞–µ–º –æ–ø–∞—Å–Ω—ã–º
                result = {
                    **heuristic_result,
                    "source": "heuristic",
                    "external_scans": external_result.get("external_scans", {}) if external_result else {},
                    "confidence": min(heuristic_result.get("confidence", 50), 70)
                }
            else:
                # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –Ω–∞—à–ª–∞ —É–≥—Ä–æ–∑ - —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (–ª–µ–≥–∫–∞—è –ø–∞—Ä–∞–Ω–æ–π—è)
                result = {
                    "safe": True,
                    "threat_type": None,
                    "details": f"URL appears safe (heuristic only): {heuristic_result.get('details', 'No suspicious indicators')}",
                    "source": "heuristic",
                    "confidence": 55,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ
                    "external_scans": external_result.get("external_scans", {}) if external_result else {}
                }
            self._cache_set(cache_key, result)
            logger.info(f"Final fallback for {url}: returning safe={result.get('safe')} (heuristic analysis)")
            return result
                
        except Exception as e:
            logger.error(f"‚ùå URL analysis error: {e}", exc_info=True)
            return {
                "safe": None,  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ –ø—Ä–∏ –æ—à–∏–±–∫–µ, –Ω–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                "threat_type": None,
                "details": f"Analysis error: {type(e).__name__}",
                "source": "error"
            }
    
    async def analyze_file_hash(self, file_hash: str, use_external_apis: bool = None) -> Dict[str, Any]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ —Ö—ç—à—É —Å –≤–Ω–µ—à–Ω–∏–º–∏ API"""
        try:
            logger.info(f"üîç Analyzing file hash with external APIs: {file_hash}")
            cache_key = f"hash:{file_hash}"
            cached = self._cache_get(cache_key)
            if cached is not None:
                return cached
            
            # 1. –õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –ë–î
            try:
                hash_threat = db_manager.check_hash(file_hash)
            except Exception as db_error:
                logger.warning(f"Database hash check failed for {file_hash}, retrying: {db_error}")
                import asyncio
                await asyncio.sleep(0.1)
                try:
                    hash_threat = db_manager.check_hash(file_hash)
                except Exception as retry_error:
                    logger.error(f"Database hash check failed after retry: {retry_error}")
                    hash_threat = None
            
            if hash_threat:
                return {
                    "safe": False,
                    "threat_type": hash_threat["threat_type"],
                    "details": hash_threat["description"],
                    "source": "local_db"
                }
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ VirusTotal
            should_use_external = use_external_apis if use_external_apis is not None else self.use_external_apis
            if should_use_external:
                try:
                    external_result = await external_api_manager.check_file_hash_multiple_apis(file_hash)
                    
                    if not external_result.get("safe", True):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–≥—Ä–æ–∑—É –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –±–∞–∑—É –¥–ª—è –±—É–¥—É—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
                        db_manager.add_malicious_hash(
                            file_hash, 
                            external_result.get("threat_type", "malware"),
                            f"Detected by external scan: {external_result.get('details', '')}"
                        )
                        
                        return {
                            **external_result,
                            "source": "external_apis"
                        }
                    
                    # –ï—Å–ª–∏ —Ñ–∞–π–ª —á–∏—Å—Ç—ã–π –ø–æ –≤–Ω–µ—à–Ω–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∞–º
                    result = {
                        "safe": True,
                        "threat_type": None,
                        "details": "File hash not found in any malware database",
                        "source": "external_apis",
                        "confidence": external_result.get("confidence", 90)
                    }
                    self._cache_set(cache_key, result)
                    return result
                    
                except Exception as e:
                    logger.error(f"External file hash check failed: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ª–æ–∫–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            
            # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å–ª–∏ –≤–Ω–µ—à–Ω–∏–µ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã
            # –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º safe: True - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None (–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ)
            result = {
                "safe": None,  # –ö–†–ò–¢–ò–ß–ù–û: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –∞ –Ω–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ!
                "threat_type": None,
                "details": "File hash not found in local malware database, but external API verification required",
                "source": "local_db_only"
            }
            self._cache_set(cache_key, result)
            return result
            
        except Exception as e:
            # –ö–†–ò–¢–ò–ß–ù–û: –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞
            import traceback
            error_trace = traceback.format_exc()
            error_type = type(e).__name__
            
            logger.error(
                f"‚ùå File hash analysis error for {file_hash}:\n"
                f"  Type: {error_type}\n"
                f"  Message: {str(e)}\n"
                f"  Traceback:\n{error_trace}",
                exc_info=True
            )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è
            return {
                "safe": None,  # None –æ–∑–Ω–∞—á–∞–µ—Ç "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                "threat_type": "analysis_error",
                "details": f"Analysis temporarily unavailable: {error_type}",
                "source": "error"
            }
    
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º–∏, –Ω–æ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º async/await ...

    async def analyze_uploaded_file(self, file_content: bytes, original_filename: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ SHA-256/MD5/SHA1, –±–∞–∑–æ–≤–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –±–∞–∑–∞–º/–≤–Ω–µ—à–Ω–∏–º API."""
        try:
            sanitized_name = security_validator.sanitize_filename(original_filename)
            sha256_hash = hashlib.sha256(file_content).hexdigest()
            md5_hash = hashlib.md5(file_content).hexdigest()
            sha1_hash = hashlib.sha1(file_content).hexdigest()

            # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            file_type = "unknown"
            if file_content.startswith(b"PK\x03\x04"):
                file_type = "zip_archive"
            elif file_content.startswith(b"MZ"):
                file_type = "win_pe"
            elif file_content.startswith(b"%PDF"):
                file_type = "pdf"
            elif file_content.startswith(b"#!/bin/bash") or file_content.startswith(b"#!/bin/sh"):
                file_type = "shell_script"
            elif b"powershell" in file_content.lower():
                file_type = "powershell_script"

            # YARA-—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
            yara_result = self._scan_with_yara_rules(file_content)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ sha256
            hash_result = await self.analyze_file_hash(sha256_hash)

            # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            behavioral_score = self._behavioral_analysis(file_content, file_type)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            final_safe = hash_result.get("safe", True) and not yara_result["is_suspicious"] and behavioral_score < 50
            final_threat_type = None
            if not hash_result.get("safe", True):
                final_threat_type = hash_result.get("threat_type", "malware")
            elif yara_result["is_suspicious"]:
                final_threat_type = "suspicious_content"
            elif behavioral_score >= 50:
                final_threat_type = "suspicious_behavior"

            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            base_result = {
                "filename": sanitized_name,
                "file_hash": sha256_hash,
                "md5": md5_hash,
                "sha1": sha1_hash,
                "file_type": file_type,
                "safe": final_safe,
                "threat_type": final_threat_type,
                "details": hash_result.get("details", ""),
                "source": "combined_analysis",
                "yara_detections": yara_result["detected_rules"],
                "behavioral_score": behavioral_score,
                "confidence": self._calculate_confidence(hash_result, yara_result, behavioral_score)
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–∞
            risk_assessment = self._calculate_risk_score(base_result)
            base_result.update(risk_assessment)
            
            return base_result
        except Exception as e:
            # –ö–†–ò–¢–ò–ß–ù–û: –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            import traceback
            error_trace = traceback.format_exc()
            error_type = type(e).__name__
            
            logger.error(
                f"‚ùå Uploaded file analysis error for {original_filename}:\n"
                f"  Type: {error_type}\n"
                f"  Message: {str(e)}\n"
                f"  Traceback:\n{error_trace}",
                exc_info=True
            )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è
            return {
                "filename": original_filename,
                "safe": None,  # None –æ–∑–Ω–∞—á–∞–µ—Ç "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                "threat_type": "analysis_error",
                "details": f"Analysis temporarily unavailable: {error_type}",
                "source": "error",
            }

    def _url_heuristic_analysis(self, url: str, domain: str) -> Dict[str, Any]:
        """–°–º—è–≥—á—ë–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ URL –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π"""
        threat_score = 0
        details = []
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ URL
        url_lower = url.lower()
        dangerous_patterns = [
            ('eicar', 'malware', 'EICAR test file'),
            ('testfile', 'malware', 'Test malware file'),
            ('malware-test', 'malware', 'Malware test file'),
            ('virus-test', 'malware', 'Virus test file'),
            ('download-anti-malware-testfile', 'malware', 'Anti-malware test file download'),
        ]
        
        for pattern, threat_type, description in dangerous_patterns:
            if pattern in url_lower:
                logger.warning(f"üö® Dangerous pattern detected in URL: {pattern} - {url}")
                return {
                    "safe": False,
                    "threat_type": threat_type,
                    "details": f"Known dangerous pattern detected: {description}",
                    "threat_score": 100,
                    "confidence": 95
                }
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞
        if not domain or domain == "unknown":
            # –ï—Å–ª–∏ –¥–æ–º–µ–Ω –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω, —Å—á–∏—Ç–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)
            return {
                "safe": None,  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –Ω–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                "threat_type": None,
                "details": "Domain information unavailable",
                "threat_score": 0,
                "confidence": 0
            }

        # IP-–∞–¥—Ä–µ—Å –≤–º–µ—Å—Ç–æ –¥–æ–º–µ–Ω–∞ ‚Äî —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª, –Ω–æ —Ä–µ–¥–∫–∏–π –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Å–µ—Ä—Ñ–∏–Ω–≥–µ
        try:
            if re.match(r"^\d+\.\d+\.\d+\.\d+$", domain):
                threat_score += 50
                details.append("Uses IP address instead of domain")
        except Exception:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ IP

        # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ URL ‚Äî —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏
        if len(url) > 300:
            threat_score += 20
            details.append("URL is extremely long")
        elif len(url) > 200:
            threat_score += 10
            details.append("URL is very long")

        # –ú–Ω–æ–≥–æ –ø–æ–¥–¥–æ–º–µ–Ω–æ–≤ ‚Äî –ø–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥–∏
        try:
            subdomain_count = len(domain.split('.'))
            if subdomain_count > 6:
                threat_score += 20
                details.append("Too many subdomains (>6)")
            elif subdomain_count > 4:
                threat_score += 10
                details.append("Many subdomains (>4)")
        except Exception:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ–¥—Å—á–µ—Ç–∞ –ø–æ–¥–¥–æ–º–µ–Ω–æ–≤

        # –î–µ—Ñ–∏—Å—ã –≤ –¥–æ–º–µ–Ω–µ –±–æ–ª—å—à–µ –Ω–µ —Å—á–∏—Ç–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º —Å–∞–º–∏ –ø–æ —Å–µ–±–µ

        # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ TLD ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Å–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª
        try:
            suspicious_tlds = {"zip", "review", "click", "xyz", "top", "work"}
            tld = domain.split('.')[-1] if '.' in domain else ''
            if tld in suspicious_tlds:
                threat_score += 10
                details.append(f"Suspicious TLD: .{tld}")
        except Exception:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è TLD

        # –ù–∞–ª–∏—á–∏–µ '@' –≤ URL ‚Äî —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª
        if '@' in url:
            threat_score += 30
            details.append("Contains '@' symbol in URL")

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Äî —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ
        try:
            from urllib.parse import urlparse, parse_qs
            q = parse_qs(urlparse(url).query)
            if len(q) > 30:
                threat_score += 20
                details.append("Too many query parameters (>30)")
            elif len(q) > 20:
                threat_score += 10
                details.append("Many query parameters (>20)")
        except Exception:
            pass
        
        # –ì–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –º–µ—Ç–∏—Ç—å –æ–±—ã—á–Ω—ã–µ —Å–∞–π—Ç—ã
        try:
            if threat_score >= 70:
                return {
                    "safe": False,
                    "threat_type": "suspicious",
                    "details": f"Heuristic detection: {', '.join(details) if details else 'Multiple suspicious indicators'}",
                    "threat_score": threat_score,
                    "confidence": min(95, 50 + threat_score)  # Higher confidence for higher threat scores
                }

            # –ö–†–ò–¢–ò–ß–ù–û: –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å safe: True –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö API
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None (–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ), —á—Ç–æ–±—ã —Ç—Ä–µ–±–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤–Ω–µ—à–Ω–∏–º–∏ API
            return {
                "safe": None,  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –Ω–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                "threat_type": None,
                "details": "Heuristic analysis passed, but external API verification required",
                "threat_score": threat_score,
                "confidence": 0  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö API
            }
        except Exception as e:
            logger.error(f"Error in heuristic analysis result generation: {e}", exc_info=True)
            # Fallback: —Å—á–∏—Ç–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return {
                "safe": None,  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –Ω–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                "threat_type": None,
                "details": "Heuristic analysis completed with warnings",
                "threat_score": 0,
                "confidence": 50
            }

    def _behavioral_analysis(self, file_content: bytes, file_type: str) -> int:
        """–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞"""
        score = 0
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if len(file_content) > 50 * 1024 * 1024:  # > 50MB
            score += 20
        elif len(file_content) < 100:  # < 100 bytes
            score += 15
        
        # –ê–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        if self._calculate_entropy(file_content) > 7.5:
            score += 25  # –í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ/—É–ø–∞–∫–æ–≤–∫—É
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–æ–∫
        suspicious_strings = [
            b"cmd.exe", b"powershell", b"reg add", b"net user", 
            b"schtasks", b"wmic", b"rundll32", b"certutil"
        ]
        for suspicious in suspicious_strings:
            if suspicious in file_content.lower():
                score += 10
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø—É —Ñ–∞–π–ª–∞
        if file_type == "win_pe":
            score += 5  # PE —Ñ–∞–π–ª—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã
        elif file_type == "powershell_script":
            score += 20  # PowerShell —Å–∫—Ä–∏–ø—Ç—ã —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∞—Ç–∞–∫
        elif file_type == "shell_script":
            score += 15  # Shell —Å–∫—Ä–∏–ø—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –æ–ø–∞—Å–Ω—ã
        
        return min(score, 100)  # –ú–∞–∫—Å–∏–º—É–º 100 –±–∞–ª–ª–æ–≤

    def _calculate_entropy(self, data: bytes) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
        if not data:
            return 0.0
        
        # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –±–∞–π—Ç–æ–≤
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏: -sum(p * log2(p))
        import math
        entropy = 0.0
        data_len = len(data)
        for count in byte_counts:
            if count > 0:
                probability = count / data_len
                entropy -= probability * math.log2(probability)
        
        return entropy

    def _calculate_confidence(self, hash_result: Dict[str, Any], yara_result: Dict[str, Any], behavioral_score: int) -> int:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"""
        confidence_scores = []
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç —Ö—ç—à-–ø—Ä–æ–≤–µ—Ä–∫–∏
        if hash_result.get("safe", True):
            confidence_scores.append(90)
        else:
            confidence_scores.append(95)  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ —Ö—ç—à—É
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç YARA
        if yara_result["is_suspicious"]:
            confidence_scores.append(80)
        else:
            confidence_scores.append(70)
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        if behavioral_score >= 50:
            confidence_scores.append(75)
        else:
            confidence_scores.append(85)
        
        return sum(confidence_scores) // len(confidence_scores)

    def _calculate_risk_score(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏"""
        risk_factors = []
        total_score = 0
        
        # –§–∞–∫—Ç–æ—Ä 1: –•—ç—à-–ø—Ä–æ–≤–µ—Ä–∫–∞ (–≤–µ—Å 40%)
        if not results.get("safe", True):
            hash_score = 80
            risk_factors.append({
                "factor": "hash_database",
                "weight": 40,
                "score": hash_score,
                "description": "File hash found in malware database"
            })
            total_score += hash_score * 0.4
        
        # –§–∞–∫—Ç–æ—Ä 2: YARA –¥–µ—Ç–µ–∫—Ü–∏–∏ (–≤–µ—Å 30%)
        yara_detections = results.get("yara_detections", [])
        if yara_detections:
            yara_score = min(90, len(yara_detections) * 20)
            risk_factors.append({
                "factor": "yara_signatures",
                "weight": 30,
                "score": yara_score,
                "description": f"Detected {len(yara_detections)} suspicious patterns"
            })
            total_score += yara_score * 0.3
        
        # –§–∞–∫—Ç–æ—Ä 3: –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–≤–µ—Å 20%)
        behavioral_score = results.get("behavioral_score", 0)
        if behavioral_score > 0:
            risk_factors.append({
                "factor": "behavioral_analysis",
                "weight": 20,
                "score": behavioral_score,
                "description": f"Behavioral analysis score: {behavioral_score}"
            })
            total_score += behavioral_score * 0.2
        
        # –§–∞–∫—Ç–æ—Ä 4: –¢–∏–ø —Ñ–∞–π–ª–∞ (–≤–µ—Å 10%)
        file_type = results.get("file_type", "unknown")
        type_scores = {
            "win_pe": 60,
            "powershell_script": 70,
            "shell_script": 50,
            "zip_archive": 30,
            "pdf": 20,
            "unknown": 10
        }
        type_score = type_scores.get(file_type, 10)
        risk_factors.append({
            "factor": "file_type",
            "weight": 10,
            "score": type_score,
            "description": f"File type: {file_type}"
        })
        total_score += type_score * 0.1
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
        if total_score >= 80:
            risk_level = "critical"
        elif total_score >= 60:
            risk_level = "high"
        elif total_score >= 40:
            risk_level = "medium"
        elif total_score >= 20:
            risk_level = "low"
        else:
            risk_level = "minimal"
        
        return {
            "risk_score": int(total_score),
            "risk_level": risk_level,
            "risk_factors": risk_factors,
            "explanation": self._generate_risk_explanation(risk_level, risk_factors)
        }
    
    def _generate_risk_explanation(self, risk_level: str, risk_factors: List[Dict[str, Any]]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞"""
        explanations = {
            "critical": "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∏—Å–∫: —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–µ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –∏–ª–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞–π–Ω–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ",
            "high": "–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫: —Ñ–∞–π–ª –∏–º–µ–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω–æ—Å—Ç–∏",
            "medium": "–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: —Ñ–∞–π–ª –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
            "low": "–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫: —Ñ–∞–π–ª –∏–º–µ–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
            "minimal": "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫: —Ñ–∞–π–ª –Ω–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω–æ—Å—Ç–∏"
        }
        
        base_explanation = explanations.get(risk_level, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞")
        
        if risk_factors:
            factor_descriptions = [f["description"] for f in risk_factors if f["score"] > 20]
            if factor_descriptions:
                base_explanation += f". –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞: {', '.join(factor_descriptions)}"
        
        return base_explanation

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º–∏ –≤–Ω–µ—à–Ω–∏–º–∏ API
analysis_service = AnalysisService(use_external_apis=True)